{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "with open('housing-data.txt', 'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "# Extract column names from the first row\n",
    "column_names = content[0].strip().split(',')\n",
    "\n",
    "# Create a list of dictionaries for each row (excluding the first row)\n",
    "data = []\n",
    "for line in content[1:]:\n",
    "\n",
    "    # Split the line into columns\n",
    "    columns = line.strip().split(',')\n",
    "\n",
    "    # Create a dictionary for the row\n",
    "    row = {}\n",
    "    for i, col_name in enumerate(column_names): \n",
    "\n",
    "        # Convert column value to numeric type\n",
    "        row[col_name] = pd.to_numeric(columns[i])\n",
    "        \n",
    "    # Add the row to the data list\n",
    "    data.append(row)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['size'], df['price'], s=10, c='b', marker='o', alpha=0.5)\n",
    "plt.xlabel('Size')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Price vs Size of houses')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the \"compute_cost\" function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    predictions = X.dot(theta)\n",
    "    square_err = (predictions - y) ** 2\n",
    "    return 1 / (2 * m) * np.sum(square_err)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's calculate the cost with theta as [0, 0]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ones'] = 1\n",
    "X = df[['ones', 'size']].values\n",
    "y = df['price'].values\n",
    "theta = np.array([0.0, 0.0])\n",
    "cost = compute_cost(X, y, theta)\n",
    "print(f\"Cost: {cost}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement the gradient_descent function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        predictions = X.dot(theta)\n",
    "        error = np.dot(X.transpose(), (predictions - y))\n",
    "        descent = alpha * 1/m * error\n",
    "        theta -= descent\n",
    "        J_history.append(compute_cost(X, y, theta))\n",
    "\n",
    "    return theta, J_history\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a plot of the values of $J(\\theta)$ that compute_costs has found.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of J(θ) values should ideally show a downward trend, steadily decreasing and eventually flattening out when the algorithm has converged to the optimal theta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "num_iters = 1000\n",
    "\n",
    "theta, J_history = gradient_descent(X, y, theta, alpha, num_iters)\n",
    "\n",
    "plt.plot(range(1, num_iters + 1), J_history, color='blue')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Cost J')\n",
    "plt.title('Cost function using Gradient Descent')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Bu we're not seeing this.\n",
    "The cost is increasing.\n",
    "it is suggested the learning rate is too high and the gradient descent algorithm is overshooting the minimum.\n",
    "\n",
    "When the learning rate is high, the algorithm takes larger steps down the cost function and might not only miss the minimum but also end up at a point where the cost is higher, leading to divergence.\n",
    "\n",
    "Try reducing the learning rate (α) and see if the algorithm starts to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(J_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the cost function values (J_history) contain inf and nan values. There are some reasons:\n",
    "\n",
    "1- The learning rate:\n",
    "earning rate that's too high. This can cause the gradient descent algorithm to take too large a step, causing numerical instability and resulting in nan values. \n",
    "\n",
    "\n",
    "2- Data Scaling: Gradient Descent is sensitive to the scale of the features.\n",
    "So i seems so important to normalize the data first and then try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'] = (df['size'] - df['size'].mean()) / df['size'].std()\n",
    "df['price'] = (df['price'] - df['price'].mean()) / df['price'].std()\n",
    "df['ones'] = 1\n",
    "X = df[['ones', 'size']].values\n",
    "y = df['price'].values\n",
    "theta = np.array([0.0, 0.0])\n",
    "cost = compute_cost(X, y, theta)\n",
    "print(f\"Cost: {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01 # decrease learning rate\n",
    "num_iters = 2000 # you can also try increasing the number of iterations\n",
    "\n",
    "theta, J_history = gradient_descent(X, y, theta, alpha, num_iters)\n",
    "\n",
    "plt.plot(range(1, num_iters + 1), J_history, color='blue')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Cost J')\n",
    "plt.title('Cost function using Gradient Descent')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can see  J(θ), decreases with each iteration. This decrease represents the algorithm getting \"closer\" to the optimal parameters for my linear regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
